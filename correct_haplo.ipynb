{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file haplo_4 not find\n",
      "    0  0\n",
      "0   C  C\n",
      "1   C  C\n",
      "2   T  T\n",
      "3   T  T\n",
      "4   T  T\n",
      ".. .. ..\n",
      "90  T  T\n",
      "91  T  T\n",
      "92  A  G\n",
      "93  C  C\n",
      "94  T  T\n",
      "\n",
      "[95 rows x 2 columns]\n",
      "    1  2\n",
      "0   C  C\n",
      "1   C  C\n",
      "2   T  T\n",
      "3   T  T\n",
      "4   T  T\n",
      ".. .. ..\n",
      "90  T  T\n",
      "91  T  T\n",
      "92  A  G\n",
      "93  C  C\n",
      "94  T  T\n",
      "\n",
      "[95 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# # Librairies\n",
    "import os\n",
    "import pandas as pd\n",
    "from argparse import ArgumentParser\n",
    "import sys\n",
    "import fnmatch\n",
    "import glob\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# recupérer le nombre de variant optimal du fichier haplo\n",
    "def optimal_variant(haplo_file):\n",
    "    numb_OptVar= int(haplo_file.split(\"_\")[1].replace(\"Variant.csv\",''))\n",
    "    return numb_OptVar\n",
    "\n",
    "\n",
    "# recupérer les variants majoritaires de chaque fichier haplo\n",
    "def maj_variants(haplo_file):\n",
    "\n",
    "    read_file=pd.read_csv(f\"{gene_dir}/{haplo_file}\", index_col=[0])\n",
    "    var_pos = read_file[\"Position\"]\n",
    "    read_file= read_file.drop(columns=[\"Position\"])\n",
    "    read_file.columns= range(1, len(read_file.columns)+1)\n",
    "    variants=[]\n",
    "    for col in read_file.columns:\n",
    "        variant= read_file[col].tolist()\n",
    "        variants.append(variant)\n",
    "    return variants, var_pos\n",
    "\n",
    "\n",
    "# print(\"****\")\n",
    "nb_replicate=5\n",
    "seuil_replicate=4\n",
    "\n",
    "freq_dir= \"/home/osidibe/work/fluGenAvi_fugace/freq_allelic_OSI\"\n",
    "\n",
    "directory = \"/home/osidibe/work/fluGenAvi_fugace/Analyse_postDESMAN_P2/DESMAN_iter\"\n",
    "gene = \"tet_44__1_NZ_ABDU01000081\"\n",
    "\n",
    "gene_dir = os.path.join(directory + \"/DESMAN_\" + gene)\n",
    "\n",
    "nb_haplo=0\n",
    "for haplo_file in os.listdir(gene_dir):\n",
    "    \n",
    "\n",
    "    if fnmatch.fnmatch(haplo_file, \"haplo_*\"):\n",
    "\n",
    "        variants , var_pos = maj_variants(haplo_file)\n",
    "    \n",
    "\n",
    "        \"\"\" Step_1 : ne pas analyser les fichiers de variants incomplets \"\"\"\n",
    "\n",
    "        if (optimal_variant(haplo_file)*int(nb_replicate)) == len(variants):\n",
    "            # print(f\"{haplo_file} bon nombre de variant\")\n",
    "            # print(len(variants))\n",
    "\n",
    "\n",
    "            \"\"\" Step_2 : Garder les haplotypes présents au moins dans 80% des réplicats  \"\"\"\n",
    "        \n",
    "            variants_not_dup = [list(x) for x in set(tuple(x) for x in variants)]\n",
    "        \n",
    "            variant_file=pd.DataFrame(var_pos)\n",
    "\n",
    "            for variant in variants_not_dup:\n",
    "                # print(variant)\n",
    "                nb_dup=0\n",
    "                for var in variants:\n",
    "                    # print(var)\n",
    "                    if variant == var:\n",
    "                        nb_dup+=1\n",
    "                \n",
    "                if nb_dup >= seuil_replicate:\n",
    "                    # variant = pd.Series(variant, index= var_pos)\n",
    "                    variant_file =pd.concat([variant_file, pd.Series(variant)], axis=1)\n",
    "                    variant_file.to_csv(f\"{gene_dir}/{haplo_file}\")\n",
    "                    \n",
    "            # print(variant_file)\n",
    "            nb_haplo+=1\n",
    "\n",
    "        \n",
    "        else :\n",
    "            os.remove(f\"{gene_dir}/{haplo_file}\")\n",
    "\n",
    "\"\"\" Step_3 : créer un fichier des variants uniques et majoritaires  \"\"\"\n",
    "\n",
    "final_variant=pd.DataFrame()\n",
    "\n",
    "nb_var=0\n",
    "\n",
    "for i in range(1, nb_haplo+1):\n",
    "    j= i+1\n",
    "    try:\n",
    "        haplo_file_1= f\"haplo_{i}Variant.csv\"\n",
    "        haplo_file_2= f\"haplo_{j}Variant.csv\"\n",
    "\n",
    "        variants_1, var_pos_1 = maj_variants(haplo_file_1)\n",
    "        # print(variants_1)\n",
    "        variants_2, var_pos_2 = maj_variants(haplo_file_2)\n",
    "        # print(variants_2)\n",
    "        # for var in variants_2:\n",
    "        commun_variant=[]\n",
    "        for var in variants_1:\n",
    "            if var in variants_2:\n",
    "                commun_variant.append(var)\n",
    "                \n",
    "            if commun_variant == variants_1:\n",
    "                nb_var+=1\n",
    "\n",
    "            else:\n",
    "                break\n",
    "\n",
    "    except FileNotFoundError: \n",
    "        print(f\"file haplo_{j} not find\")\n",
    "\n",
    "if nb_var == 0:\n",
    "    final_variant = pd.concat([final_variant, pd.Series(var)], axis=1)\n",
    "\n",
    "elif nb_var != 0:       \n",
    "    for var in variants_2:\n",
    "        final_variant = pd.concat([final_variant, pd.Series(var)], axis=1)     \n",
    "\n",
    "final_variant.to_csv(f\"{gene_dir}/final_variant.csv\")\n",
    "print(final_variant)\n",
    "\n",
    "\"\"\" Step_4: vérifier si les variants majoritaires sont correctements reconstruits  \"\"\"\n",
    "\n",
    "# Ouvrir les tables de comptages\n",
    "freq_repository = glob.glob(f\"{freq_dir}/*\")\n",
    "final_variant.columns = range(1, len(final_variant.columns)+1)\n",
    "\n",
    "nb_var=0\n",
    "for col in final_variant.columns:\n",
    "\n",
    "    nb_base=0\n",
    "    index_var=0\n",
    "    for base in final_variant[col].tolist():\n",
    "\n",
    "        for freq in freq_repository:\n",
    "            try:\n",
    "                comptage = pd.read_csv(f\"{freq}/{gene}.freq\", sep=\"\\t\", index_col=[0])\n",
    "\n",
    "                if var_pos[index_var] in comptage.index:\n",
    "                    if comptage.loc[var_pos[index_var],base] != 0:\n",
    "                        nb_base+=1\n",
    "                        index_var+=1\n",
    "                        break\n",
    "                    \n",
    "            except FileNotFoundError :\n",
    "                print(f\"{freq}/{gene}.freq not exist or position not exit in file\")\n",
    "\n",
    "    if nb_base == len(final_variant.index):\n",
    "        nb_var+=1\n",
    "        \n",
    "\n",
    "    else :\n",
    "        final_variant=final_variant.drop(columns=col, axis=1)\n",
    "\n",
    "if nb_var == len(final_variant.columns):\n",
    "    # print(\"All variant correct\")\n",
    "    final_variant.to_csv(f\"{gene_dir}/final_variant.csv\")\n",
    "    print(final_variant)\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/osidibe/work/fluGenAvi_fugace/freq_allelic_OSI/CTU_ACI/erm_F__3_M17808.freq not Found\n",
      "/home/osidibe/work/fluGenAvi_fugace/freq_allelic_OSI/CTU_ACI/erm_F__3_M17808.freq not Found\n",
      "/home/osidibe/work/fluGenAvi_fugace/freq_allelic_OSI/CTU_ACI/erm_F__3_M17808.freq not Found\n",
      "/home/osidibe/work/fluGenAvi_fugace/freq_allelic_OSI/CTU_ACI/erm_F__3_M17808.freq not Found\n",
      "/home/osidibe/work/fluGenAvi_fugace/freq_allelic_OSI/CTU_ACI/erm_F__3_M17808.freq not Found\n",
      "/home/osidibe/work/fluGenAvi_fugace/freq_allelic_OSI/CTU_ACI/erm_F__3_M17808.freq not Found\n",
      "/home/osidibe/work/fluGenAvi_fugace/freq_allelic_OSI/CTU_ACI/erm_F__3_M17808.freq not Found\n",
      "/home/osidibe/work/fluGenAvi_fugace/freq_allelic_OSI/CTU_ACI/erm_F__3_M17808.freq not Found\n",
      "/home/osidibe/work/fluGenAvi_fugace/freq_allelic_OSI/CTU_ACI/erm_F__3_M17808.freq not Found\n",
      "All variant correct\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Step_4: vérifier si les variants majoritaires sont correctements reconstruits  \"\"\"\n",
    "\n",
    "# Ouvrir les tables de comptages\n",
    "freq_repository = glob.glob(f\"{freq_dir}/*\")\n",
    "nb_var=0\n",
    "for col in range(1, len(final_variant.columns)+1):\n",
    "\n",
    "    nb_base=0\n",
    "    index_var = 0\n",
    "\n",
    "    for base in final_variant[col].tolist():\n",
    "\n",
    "        for freq in freq_repository:\n",
    "            try:\n",
    "                comptage = pd.read_csv(f\"{freq}/{gene}.freq\", sep=\"\\t\", index_col=[0])\n",
    "\n",
    "            except FileNotFoundError :\n",
    "                print(f\"{freq}/{gene}.freq not Found\")\n",
    "\n",
    "\n",
    "            if comptage.loc[var_pos[index_var],base] != 0 :\n",
    "                # print(f\"{base} is correct\")\n",
    "                nb_base+=1\n",
    "                index_var+=1\n",
    "                break\n",
    "\n",
    "    if nb_base == len(final_variant.index):\n",
    "        # print(f\"{final_variant[col]} is correct variant\")\n",
    "        nb_var+=1\n",
    "\n",
    "    else :\n",
    "        final_variant=final_variant.drop(final_variant[col])\n",
    "        # print(f\"{final_variant[col]} is incorrect variant\")\n",
    "\n",
    "if nb_var == len(final_variant.columns):\n",
    "    print(\"All variant correct\")\n",
    "\n",
    "final_variant.to_csv(f\"{gene_dir}/final_variant.csv\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
